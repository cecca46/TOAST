{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from spatial_OT.OT import *\n",
    "from spatial_OT.utils import *\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consecutive = [[\"151507\", \"151508\"], [\"151508\", \"151509\"], [\"151509\", \"151510\"],\n",
    "                [\"151669\", \"151670\"], [\"151670\", \"151671\"], [\"151671\", \"151672\"],\n",
    "                [\"151673\", \"151674\"], [\"151674\", \"151675\"], [\"151675\", \"151676\"]]\n",
    "\n",
    "non_consecutive = [[\"151507\", \"151509\"], [\"151507\", \"151510\"], [\"151508\", \"151510\"],\n",
    "                [\"151669\", \"151671\"], [\"151669\", \"151672\"], [\"151670\", \"151672\"],\n",
    "                [\"151673\", \"151675\"], [\"151673\", \"151676\"], [\"151674\", \"151676\"]]\n",
    "\n",
    "cross_sample = [[\"151507\", \"151669\"], [\"151507\", \"151673\"], [\"151669\", \"151673\"],\n",
    "                [\"151508\", \"151670\"], [\"151508\", \"151674\"], [\"151670\", \"151674\"],\n",
    "                [\"151509\", \"151671\"], [\"151509\", \"151675\"], [\"151671\", \"151675\"],\n",
    "                [\"151510\", \"151672\"], [\"151510\", \"151676\"], [\"151672\", \"151676\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "results = []\n",
    "\n",
    "def process_slice(slice_path):\n",
    "    \"\"\"Load and preprocess a spatial transcriptomics slice.\"\"\"\n",
    "    slice_data = sc.read_visium(path=f\"../LIBD/{slice_path}\", count_file=f\"{slice_path}_filtered_feature_bc_matrix.h5\")\n",
    "    slice_data.obs_names_make_unique()\n",
    "    slice_data.var_names_make_unique()\n",
    "    \n",
    "    ann = pd.read_csv(f\"../LIBD/{slice_path}/{slice_path}_truth.txt\", sep='\\t', header=None, index_col=0)\n",
    "    slice_data.obs[\"gt\"] = ann.loc[slice_data.obs.index, 1]\n",
    "    \n",
    "    # Remove NA cells\n",
    "    slice_data = slice_data[~slice_data.obs[\"gt\"].isna()]\n",
    "    \n",
    "    return slice_data\n",
    "\n",
    "def compute_spatial_fgw_alignment(slice1, slice2, alpha, epsilon):\n",
    "    \"\"\"Compute FGW and FGW-SN alignment and return accuracy and JS divergence scores.\"\"\"\n",
    "    joint_adata = sc.concat([slice1, slice2])\n",
    "    sc.pp.normalize_total(joint_adata, inplace=True)\n",
    "    sc.pp.log1p(joint_adata)\n",
    "    sc.pp.pca(joint_adata, n_comps=n_comps)\n",
    "    joint_datamatrix = joint_adata.obsm['X_pca']\n",
    "    \n",
    "    X = joint_datamatrix[:slice1.shape[0], :]\n",
    "    Y = joint_datamatrix[slice1.shape[0]:, :]\n",
    "    \n",
    "    # Compute spatial graphs\n",
    "    coords1 = pd.DataFrame(slice1.obsm[\"spatial\"], columns=[\"x\", \"y\"])\n",
    "    X_df = pd.DataFrame(X, columns=[f\"PC{i+1}\" for i in range(X.shape[1])])\n",
    "    X_df[\"x\"], X_df[\"y\"], X_df[\"cell_type\"] = coords1[\"x\"].values, coords1[\"y\"].values, slice1.obs[\"gt\"].values\n",
    "\n",
    "    G1 = build_knn_graph_from2d(X_df, k=k)\n",
    "    X_df[\"spatial_entropy\"] = X_df.index.map(compute_spatial_entropy(G1))\n",
    "    slice1_avg_expr = compute_average_neighbor_expression(G1, pd.DataFrame(X))\n",
    "    \n",
    "    coords2 = pd.DataFrame(slice2.obsm[\"spatial\"], columns=[\"x\", \"y\"])\n",
    "    Y_df = pd.DataFrame(Y, columns=[f\"PC{i+1}\" for i in range(Y.shape[1])])\n",
    "    Y_df[\"x\"], Y_df[\"y\"], Y_df[\"cell_type\"] = coords2[\"x\"].values, coords2[\"y\"].values, slice2.obs[\"gt\"].values\n",
    "\n",
    "    G2 = build_knn_graph_from2d(Y_df, k=k)\n",
    "    Y_df[\"spatial_entropy\"] = Y_df.index.map(compute_spatial_entropy(G2))\n",
    "    slice2_avg_expr = compute_average_neighbor_expression(G2, pd.DataFrame(Y))\n",
    "    \n",
    "    # Compute cost matrices\n",
    "    M = distance.cdist(X, Y).astype(float)\n",
    "    C1 = distance.cdist(slice1.obsm[\"spatial\"], slice1.obsm[\"spatial\"]).astype(float)\n",
    "    C2 = distance.cdist(slice2.obsm[\"spatial\"], slice2.obsm[\"spatial\"]).astype(float)\n",
    "    C3 = np.abs(X_df[\"spatial_entropy\"].values[:, np.newaxis] - Y_df[\"spatial_entropy\"].values[np.newaxis, :])\n",
    "    C4 = distance.cdist(slice1_avg_expr.values, slice2_avg_expr.values).astype(float)\n",
    "\n",
    "    # Normalize matrices\n",
    "    for mat in [M, C1, C2, C3, C4]:\n",
    "        mat /= mat.max() if mat.max() > 0 else 1  # Avoid division by zero\n",
    "    \n",
    "    # Compute transport maps\n",
    "    p, q = ot.unif(X.shape[0]), ot.unif(Y.shape[0])\n",
    "    G0 = np.outer(p, q)\n",
    "\n",
    "    FGW = compute_transport(G0, epsilon, alpha, C1, C2, p, q, M)\n",
    "    FGW_SN = compute_transport(G0, epsilon, alpha, C1, C2, p, q, M, C3, C4)\n",
    "\n",
    "    # Compute accuracy\n",
    "    acc_fgw = compute_accuracy_max_prob(FGW, slice1.obs['gt'], slice2.obs['gt'])\n",
    "    acc_fgw_sn = compute_accuracy_max_prob(FGW_SN, slice1.obs['gt'], slice2.obs['gt'])\n",
    "    \n",
    "    # Compute JS divergence\n",
    "    js_fgw = compute_js_divergence_before_after(slice1, compute_transported_adata_argmax(slice1, slice2, FGW), k=20, cell_type_key=\"gt\")\n",
    "    js_fgw_sn = compute_js_divergence_before_after(slice1, compute_transported_adata_argmax(slice1, slice2, FGW_SN), k=20, cell_type_key=\"gt\")\n",
    "\n",
    "    return acc_fgw, acc_fgw_sn, js_fgw, js_fgw_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alignment: 151507 - 151508\n",
      "FGW Accuracy: 0.654, FGW-SN Accuracy: 0.735\n",
      "FGW JS Divergence: 0.3268, FGW-SN JS Divergence: 0.2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_comps = 50  \n",
    "k = 10 \n",
    "alpha = 0.5  \n",
    "epsilon = 0.1  \n",
    "\n",
    "# Run for all consecutive slices\n",
    "for i in consecutive:\n",
    "    print(f\"Processing alignment: {i[0]} - {i[1]}\")\n",
    "    \n",
    "    # Load and process slices\n",
    "    slice1 = process_slice(i[0])\n",
    "    slice2 = process_slice(i[1])\n",
    "\n",
    "    # Compute alignment\n",
    "    acc_fgw, acc_fgw_sn, js_fgw, js_fgw_sn = compute_spatial_fgw_alignment(slice1, slice2, alpha, epsilon)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Slice1\": i[0], \"Slice2\": i[1],\n",
    "        \"FGW_Accuracy\": acc_fgw, \"FGW-SN_Accuracy\": acc_fgw_sn,\n",
    "        \"FGW_JS_Divergence\": js_fgw, \"FGW-SN_JS_Divergence\": js_fgw_sn\n",
    "    })\n",
    "\n",
    "    print(f\"FGW Accuracy: {acc_fgw:.3f}, FGW-SN Accuracy: {acc_fgw_sn:.3f}\")\n",
    "    print(f\"FGW JS Divergence: {js_fgw:.4f}, FGW-SN JS Divergence: {js_fgw_sn:.4f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visium",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
